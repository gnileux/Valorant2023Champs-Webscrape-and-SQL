from bs4 import BeautifulSoup
import requests
import pandas as pd

# load the vlr webpage content 
source=requests.get('https://www.vlr.gg/event/stats/466/valorant-champions-tour-stage-3-masters-berlin').text

#convert to beautiful soup
soup = BeautifulSoup(source,'lxml')

table = soup.find('table', {'class':'wf-table mod-stats mod-scroll'})

headers = []

for i in table.find_all('th'):
    title = i.text.strip()
    headers.append(title)

df = pd.DataFrame(columns=headers)

#loop through all tr starting from the second one and find all data for each row. Data is 156 players/rows x 21 stats/columns
#strip numbers for player and each column
#length at 0, input row data at row 0 for first player and so on
#length has 156 rows, looped through each row of table to add all 156 rows to the dataframe
for row in table.find_all('tr')[1:]:
    data = row.find_all('td')
    row_data = [td.text.strip() for td in data]
    length = len(df)
    df.loc[length] = row_data

print(df)
df = pd.DataFrame(df)
df.to_csv('table.csv')
csv = df.to_csv('table.csv')
print(csv)
